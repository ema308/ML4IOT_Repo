{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"84853ec962fb4050b66065f024576a4c","deepnote_cell_type":"markdown"},"source":"# Keras API with Callbacks","block_group":"28c26017e2ef4b2d9b095c80f892b4b5"},{"cell_type":"markdown","metadata":{"cell_id":"864c830e7af44319baa26cc7e043fbf5","deepnote_cell_type":"markdown"},"source":"### Import the required modules","block_group":"44493e1571534fafa88009d15050acb5"},{"cell_type":"code","metadata":{"source_hash":"924eb9cf","execution_start":1733756564051,"execution_millis":0,"execution_context_id":"02435cd0-a643-464f-a2a2-2611cdf83c53","deepnote_to_be_reexecuted":false,"cell_id":"6a6976a58ef04bf4844697c7d470cb07","deepnote_cell_type":"code"},"source":"import tensorflow as tf\nfrom reader import AudioReader\nfrom preprocessing import Padding, Normalization\nfrom preprocessing import MFCC","block_group":"633feea765cc458d83cc8286f498e701","execution_count":128,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"df35f1d6b1fc4756be73683810832477","deepnote_cell_type":"markdown"},"source":"### Define the Hyperparameters","block_group":"3893cdaa0fb643d5a7a0e1bab7f58cf7"},{"cell_type":"code","metadata":{"source_hash":"b3d21622","execution_start":1733756568325,"execution_millis":2,"execution_context_id":"02435cd0-a643-464f-a2a2-2611cdf83c53","cell_id":"e7140b6e6b6142aca1c0f39b0608cc4e","deepnote_cell_type":"code"},"source":"PREPROCESSING_ARGS = {\n    'sampling_rate': 16000,\n    'frame_length_in_s': 0.032,\n    'frame_step_in_s': 0.016,\n    'num_mel_bins': 21,\n    'lower_frequency': 40,\n    'upper_frequency': 5000,\n    'num_coefficients': 14\n}\n\nTRAINING_ARGS = {\n    'batch_size': 20,\n    'learning_rate': 0.01,\n    'end_learning_rate': 1.e-5,\n    'epochs': 20,\n    'width_multiplier': 0.4,\n    'begin_step_%': 0.1,\n    'end_step_%': 0.9,\n    'initial_sparsity': 0.10,\n    'final_sparsity': 0.82\n}","block_group":"ad7b86abd8904bbab87f594d9fd57774","execution_count":129,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"026685dee7534240aa6bef85b958f67b","deepnote_cell_type":"markdown"},"source":"### Create train/val/test Datasets","block_group":"66b565ed03f64623a1b85be27d91c6fd"},{"cell_type":"code","metadata":{"source_hash":"92026362","execution_start":1733756572420,"execution_millis":157,"execution_context_id":"02435cd0-a643-464f-a2a2-2611cdf83c53","cell_id":"60a6cab28d694c4ab4193995c5c68558","deepnote_cell_type":"code"},"source":"train_ds = tf.data.Dataset.list_files(['/tmp/msc-train/*down*', '/tmp/msc-train/*up*'])\nval_ds = tf.data.Dataset.list_files(['/tmp/msc-val/*down*', '/tmp/msc-val/*up*'])\ntest_ds = tf.data.Dataset.list_files(['/tmp/msc-test/*down*', '/tmp/msc-test/*up*'])","block_group":"0e9b5465f91d4a0db24d84679c19ae4f","execution_count":130,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"3d3e382501554ae59c554957a5911421","deepnote_cell_type":"markdown"},"source":"### Define the Data Pipeline","block_group":"97e1d42b367f476aa48514d5ebcc58fd"},{"cell_type":"code","metadata":{"source_hash":"eea32814","execution_start":1733756577976,"execution_millis":839,"execution_context_id":"02435cd0-a643-464f-a2a2-2611cdf83c53","cell_id":"0c50767ee1b542ee968bf67be34f8bfd","deepnote_cell_type":"code"},"source":"!ls /tmp/msc-train/* | head -n5\n!ls /tmp/msc-val/* | head -n5\n!ls /tmp/msc-test/* | head -n5","block_group":"5475f6f380374803b4662941b00d1234","execution_count":131,"outputs":[{"name":"stdout","text":"/tmp/msc-train/down_004ae714_nohash_0.wav\n/tmp/msc-train/down_00b01445_nohash_1.wav\n/tmp/msc-train/down_00f0204f_nohash_0.wav\n/tmp/msc-train/down_0132a06d_nohash_1.wav\n/tmp/msc-train/down_0137b3f4_nohash_2.wav\nls: write error: Broken pipe\n/tmp/msc-val/down_0132a06d_nohash_4.wav\n/tmp/msc-val/down_063d48cf_nohash_0.wav\n/tmp/msc-val/down_0a9f9af7_nohash_0.wav\n/tmp/msc-val/down_0ff728b5_nohash_4.wav\n/tmp/msc-val/down_14872d06_nohash_0.wav\nls: write error: Broken pipe\n/tmp/msc-test/down_099d52ad_nohash_2.wav\n/tmp/msc-test/down_0ff728b5_nohash_3.wav\n/tmp/msc-test/down_10ace7eb_nohash_3.wav\n/tmp/msc-test/down_14587ff0_nohash_0.wav\n/tmp/msc-test/down_19e246ad_nohash_0.wav\nls: write error: Broken pipe\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/6e60dd23-8f32-4f97-952b-13c9efb3c8d0","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"5d43f26861fb416f8aab13827ddf04eb","deepnote_cell_type":"markdown"},"source":"### Read a batch of data","block_group":"f181884009874a0fb92815d92adf26c3"},{"cell_type":"code","metadata":{"source_hash":"a4b2d776","execution_start":1733756583597,"execution_millis":742,"execution_context_id":"02435cd0-a643-464f-a2a2-2611cdf83c53","cell_id":"03410741e6df4e469255bd5a3a3b5bb5","deepnote_cell_type":"code"},"source":"audio_reader = AudioReader(tf.int16)\npadding = Padding(PREPROCESSING_ARGS['sampling_rate'])\nnormalization = Normalization(tf.int16)\n#mel_spec_processor = MelSpectrogram(**PREPROCESSING_ARGS)\nmfcc_processor = MFCC(**PREPROCESSING_ARGS)\n\nLABELS = ['down', 'up']\n\ndef prepare_for_training(feature, label):\n    feature = tf.expand_dims(feature, -1)\n    label_id = tf.argmax(label == LABELS)\n\n    return feature, label_id\n\ntrain_ds = (train_ds\n            .map(audio_reader.get_audio_and_label)\n            .map(padding.pad)\n            .map(normalization.normalize)\n            .map(mfcc_processor.get_mfccs_and_label)\n            .map(prepare_for_training)\n            .batch(TRAINING_ARGS['batch_size'])\n            .cache())\nval_ds = (val_ds\n            .map(audio_reader.get_audio_and_label)\n            .map(padding.pad)\n            .map(normalization.normalize)\n            .map(mfcc_processor.get_mfccs_and_label)\n            .map(prepare_for_training)\n            .batch(TRAINING_ARGS['batch_size']))\ntest_ds = (test_ds\n            .map(audio_reader.get_audio_and_label)\n            .map(padding.pad)\n            .map(normalization.normalize)\n            .map(mfcc_processor.get_mfccs_and_label)\n            .map(prepare_for_training)\n            .batch(TRAINING_ARGS['batch_size']))","block_group":"f5e542ce853641aa85640fd46c858843","execution_count":132,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"9dead3aa","execution_start":1733756588492,"execution_millis":208,"execution_context_id":"02435cd0-a643-464f-a2a2-2611cdf83c53","cell_id":"13de7c9139624ddb895bba6b5b033084","deepnote_cell_type":"code"},"source":"for example_batch, example_labels in train_ds.take(1):\n  print('Batch Shape:', example_batch.shape)\n  print('Data Shape:', example_batch.shape[1:])\n  print('Labels:', example_labels)","block_group":"e94f7420dd4c4b2ca86f01f38018c44e","execution_count":133,"outputs":[{"name":"stdout","text":"Batch Shape: (20, 61, 14, 1)\nData Shape: (61, 14, 1)\nLabels: tf.Tensor([1 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 1 1 0 1], shape=(20,), dtype=int64)\n2024-12-09 15:03:08.683062: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/3ba6be12-6ca4-4fbf-8bc9-e0ce829c1854","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"2d9fc393c08c4f9e8d3079d8c7f89c73","deepnote_cell_type":"markdown"},"source":"### Create the Model","block_group":"700506acf8e24a91bf0ab8bd8ba1226a"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"0a5f89075c154e668355b7a00c68ecd5","deepnote_cell_type":"text-cell-p"},"source":"sequential convolutional NN","block_group":"026c273522f5473fb0231475c0368bde"},{"cell_type":"code","metadata":{"source_hash":"2d9f4313","execution_start":1733756593066,"execution_millis":62,"execution_context_id":"02435cd0-a643-464f-a2a2-2611cdf83c53","cell_id":"19ca82b411464e0ba759ffe4a76514e9","deepnote_cell_type":"code"},"source":"wm = TRAINING_ARGS['width_multiplier']\n\nmodel = tf.keras.Sequential([ ##width multiplier and model for pruning nelle funz successive \n    tf.keras.layers.Input(shape=example_batch.shape[1:]),\n    tf.keras.layers.Conv2D(filters=int(256 * wm), kernel_size=[3, 3], strides=[2, 2],\n        use_bias=False, padding='valid'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.ReLU(),\n    tf.keras.layers.DepthwiseConv2D(kernel_size=[3, 3], strides=[1, 1], \n        use_bias=False, padding='same'),\n    tf.keras.layers.Conv2D(filters=int(256 * wm), kernel_size=[1, 1], strides=[1, 1],   \n       use_bias=False),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.ReLU(),\n    tf.keras.layers.DepthwiseConv2D(kernel_size=[3, 3], strides=[1, 1],\n        use_bias=False, padding='same'),\n    tf.keras.layers.Conv2D(filters=int(256 * wm), kernel_size=[1, 1], strides=[1, 1],   \n       use_bias=False),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.ReLU(),\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(units=len(LABELS)),\n    tf.keras.layers.Softmax()\n])","block_group":"ecec6f8cea0044d0be859d7c3935fccd","execution_count":134,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"72debf1349b54ab98951ecf2a6b48365","deepnote_cell_type":"text-cell-h3"},"source":"### Setup for pruning","block_group":"1873771a00a54bfa8e492eb4547cddda"},{"cell_type":"code","metadata":{"source_hash":"8aab2c6b","execution_start":1733756596917,"execution_millis":116,"execution_context_id":"02435cd0-a643-464f-a2a2-2611cdf83c53","cell_id":"b1d4cd51012e41c0953ca6f8b50ed8c7","deepnote_cell_type":"code"},"source":"import tensorflow_model_optimization as tfmot\n\nprune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n\nbegin_step = int(len(train_ds) * TRAINING_ARGS['epochs'] * TRAINING_ARGS['begin_step_%'])\nend_step = int(len(train_ds) * TRAINING_ARGS['epochs'] * TRAINING_ARGS['end_step_%'])\n\npruning_params = {\n    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n        initial_sparsity=TRAINING_ARGS['initial_sparsity'],\n        final_sparsity=TRAINING_ARGS['final_sparsity'],\n        begin_step=begin_step,\n        end_step=end_step\n    )\n}\n\n#wm = TRAINING_ARGS['width_multiplier']\n\nmodel_for_pruning = prune_low_magnitude(model, **pruning_params)","block_group":"230ee178785d434981b8c8773c00691b","execution_count":135,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"7693b3ac","execution_start":1733506528191,"execution_millis":86,"execution_context_id":"2cf91b3b-32b6-4328-a2ae-eda3e2a6285c","cell_id":"07d27b3f09914a27b293ad8933938e21","deepnote_cell_type":"code"},"source":"model_for_pruning.summary() ","block_group":"47b5b2b66ffc4f3c9146bd6d04f9a1bd","execution_count":30,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n prune_low_magnitude_conv2d  (None, 30, 9, 102)        1838      \n _3 (PruneLowMagnitude)                                          \n                                                                 \n prune_low_magnitude_batch_  (None, 30, 9, 102)        409       \n normalization_3 (PruneLowM                                      \n agnitude)                                                       \n                                                                 \n prune_low_magnitude_re_lu_  (None, 30, 9, 102)        1         \n 3 (PruneLowMagnitude)                                           \n                                                                 \n prune_low_magnitude_depthw  (None, 30, 9, 102)        919       \n ise_conv2d_2 (PruneLowMagn                                      \n itude)                                                          \n                                                                 \n prune_low_magnitude_conv2d  (None, 30, 9, 102)        20810     \n _4 (PruneLowMagnitude)                                          \n                                                                 \n prune_low_magnitude_batch_  (None, 30, 9, 102)        409       \n normalization_4 (PruneLowM                                      \n agnitude)                                                       \n                                                                 \n prune_low_magnitude_re_lu_  (None, 30, 9, 102)        1         \n 4 (PruneLowMagnitude)                                           \n                                                                 \n prune_low_magnitude_depthw  (None, 30, 9, 102)        919       \n ise_conv2d_3 (PruneLowMagn                                      \n itude)                                                          \n                                                                 \n prune_low_magnitude_conv2d  (None, 30, 9, 102)        20810     \n _5 (PruneLowMagnitude)                                          \n                                                                 \n prune_low_magnitude_batch_  (None, 30, 9, 102)        409       \n normalization_5 (PruneLowM                                      \n agnitude)                                                       \n                                                                 \n prune_low_magnitude_re_lu_  (None, 30, 9, 102)        1         \n 5 (PruneLowMagnitude)                                           \n                                                                 \n prune_low_magnitude_global  (None, 102)               1         \n _average_pooling2d_1 (Prun                                      \n eLowMagnitude)                                                  \n                                                                 \n prune_low_magnitude_dense_  (None, 2)                 412       \n 1 (PruneLowMagnitude)                                           \n                                                                 \n prune_low_magnitude_softma  (None, 2)                 1         \n x_1 (PruneLowMagnitude)                                         \n                                                                 \n=================================================================\nTotal params: 46940 (183.41 KB)\nTrainable params: 24380 (95.23 KB)\nNon-trainable params: 22560 (88.18 KB)\n_________________________________________________________________\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/75860549-08d6-4cff-9d9a-c4435596fdc8","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"353df795da3e4b5e96d843cab4400083","deepnote_cell_type":"markdown"},"source":"### Create callbacks","block_group":"b96b806a31374304a84023ca33201108"},{"cell_type":"code","metadata":{"source_hash":"fa79d21c","execution_start":1733756604847,"execution_millis":1,"execution_context_id":"02435cd0-a643-464f-a2a2-2611cdf83c53","cell_id":"bf3b153dd12e44bfb490dcb50804e624","deepnote_cell_type":"code"},"source":"# Learning Rate scheduler\nlinear_decay = tf.keras.optimizers.schedules.PolynomialDecay(\n    initial_learning_rate=TRAINING_ARGS['learning_rate'],\n    end_learning_rate=TRAINING_ARGS['end_learning_rate'],\n    decay_steps=len(train_ds) * TRAINING_ARGS['epochs'],\n)\nlr_scheduler = tf.keras.callbacks.LearningRateScheduler(linear_decay)\n\n# Early Stopping\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=5,\n    verbose=1,\n    mode='auto'\n)","block_group":"69773b2004154973a64121ee6604e88e","execution_count":136,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"26419fc11835432eb73362167cc9421e","deepnote_cell_type":"markdown"},"source":"### Train the Model (with Callbacks)\n\n- Modify the `learning_rate` argument of the `Adam` optimizer.\n- Modify the `fit` method, specifying the `callbacks` argument.","block_group":"0a76a31e6cb840e3826f7dc0a72f384a"},{"cell_type":"code","metadata":{"source_hash":"c9c65536","execution_start":1733756614955,"execution_millis":133452,"execution_context_id":"02435cd0-a643-464f-a2a2-2611cdf83c53","cell_id":"8f51c0d61ed543be839230105d884016","deepnote_cell_type":"code"},"source":"loss = tf.losses.SparseCategoricalCrossentropy(from_logits=False)\noptimizer = tf.optimizers.Adam(learning_rate=linear_decay)\nmetrics = [tf.metrics.SparseCategoricalAccuracy()]\nmodel_for_pruning.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n\nupdate_pruning_step = tfmot.sparsity.keras.UpdatePruningStep()\n\nhistory = model_for_pruning.fit(\n    train_ds, \n    epochs=TRAINING_ARGS['epochs'], \n    validation_data=val_ds, \n    callbacks=[lr_scheduler, early_stopping, update_pruning_step]\n)","block_group":"e2f8312e96b44616bf39e7a65b93c794","execution_count":137,"outputs":[{"name":"stdout","text":"Epoch 1/20\n80/80 [==============================] - 12s 112ms/step - loss: 0.4559 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.5974 - val_sparse_categorical_accuracy: 0.7350 - lr: 0.0095\nEpoch 2/20\n80/80 [==============================] - 5s 66ms/step - loss: 0.2876 - sparse_categorical_accuracy: 0.8956 - val_loss: 1.6708 - val_sparse_categorical_accuracy: 0.6200 - lr: 0.0090\nEpoch 3/20\n80/80 [==============================] - 5s 65ms/step - loss: 0.2089 - sparse_categorical_accuracy: 0.9362 - val_loss: 0.3793 - val_sparse_categorical_accuracy: 0.8600 - lr: 0.0085\nEpoch 4/20\n80/80 [==============================] - 5s 67ms/step - loss: 0.1334 - sparse_categorical_accuracy: 0.9538 - val_loss: 0.2412 - val_sparse_categorical_accuracy: 0.9250 - lr: 0.0080\nEpoch 5/20\n80/80 [==============================] - 5s 67ms/step - loss: 0.0969 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.2452 - val_sparse_categorical_accuracy: 0.9250 - lr: 0.0075\nEpoch 6/20\n80/80 [==============================] - 5s 64ms/step - loss: 0.0752 - sparse_categorical_accuracy: 0.9669 - val_loss: 0.1137 - val_sparse_categorical_accuracy: 0.9550 - lr: 0.0070\nEpoch 7/20\n80/80 [==============================] - 5s 66ms/step - loss: 0.0623 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.1620 - val_sparse_categorical_accuracy: 0.9450 - lr: 0.0065\nEpoch 8/20\n80/80 [==============================] - 5s 65ms/step - loss: 0.0546 - sparse_categorical_accuracy: 0.9800 - val_loss: 0.1032 - val_sparse_categorical_accuracy: 0.9600 - lr: 0.0060\nEpoch 9/20\n80/80 [==============================] - 5s 69ms/step - loss: 0.0541 - sparse_categorical_accuracy: 0.9831 - val_loss: 0.1089 - val_sparse_categorical_accuracy: 0.9500 - lr: 0.0055\nEpoch 10/20\n80/80 [==============================] - 5s 68ms/step - loss: 0.0555 - sparse_categorical_accuracy: 0.9800 - val_loss: 0.0912 - val_sparse_categorical_accuracy: 0.9700 - lr: 0.0050\nEpoch 11/20\n80/80 [==============================] - 5s 67ms/step - loss: 0.0596 - sparse_categorical_accuracy: 0.9825 - val_loss: 0.1190 - val_sparse_categorical_accuracy: 0.9500 - lr: 0.0045\nEpoch 12/20\n80/80 [==============================] - 6s 69ms/step - loss: 0.0524 - sparse_categorical_accuracy: 0.9825 - val_loss: 0.0916 - val_sparse_categorical_accuracy: 0.9700 - lr: 0.0040\nEpoch 13/20\n80/80 [==============================] - 5s 67ms/step - loss: 0.0493 - sparse_categorical_accuracy: 0.9831 - val_loss: 0.0881 - val_sparse_categorical_accuracy: 0.9650 - lr: 0.0035\nEpoch 14/20\n80/80 [==============================] - 5s 67ms/step - loss: 0.0414 - sparse_categorical_accuracy: 0.9887 - val_loss: 0.0621 - val_sparse_categorical_accuracy: 0.9650 - lr: 0.0030\nEpoch 15/20\n80/80 [==============================] - 5s 68ms/step - loss: 0.0353 - sparse_categorical_accuracy: 0.9900 - val_loss: 0.0535 - val_sparse_categorical_accuracy: 0.9750 - lr: 0.0025\nEpoch 16/20\n80/80 [==============================] - 5s 66ms/step - loss: 0.0346 - sparse_categorical_accuracy: 0.9887 - val_loss: 0.0705 - val_sparse_categorical_accuracy: 0.9650 - lr: 0.0020\nEpoch 17/20\n80/80 [==============================] - 5s 68ms/step - loss: 0.0296 - sparse_categorical_accuracy: 0.9919 - val_loss: 0.0518 - val_sparse_categorical_accuracy: 0.9750 - lr: 0.0015\nEpoch 18/20\n80/80 [==============================] - 5s 67ms/step - loss: 0.0275 - sparse_categorical_accuracy: 0.9919 - val_loss: 0.0591 - val_sparse_categorical_accuracy: 0.9650 - lr: 0.0010\nEpoch 19/20\n80/80 [==============================] - 5s 66ms/step - loss: 0.0244 - sparse_categorical_accuracy: 0.9925 - val_loss: 0.0502 - val_sparse_categorical_accuracy: 0.9800 - lr: 5.1574e-04\nEpoch 20/20\n80/80 [==============================] - 5s 65ms/step - loss: 0.0230 - sparse_categorical_accuracy: 0.9937 - val_loss: 0.0479 - val_sparse_categorical_accuracy: 0.9800 - lr: 1.6244e-05\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/844a6458-9252-4419-bbc6-030d04e4692f","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"3824183c36f7493ca26bed720afe40f6","deepnote_cell_type":"markdown"},"source":"### Show the History","block_group":"f534087411e34c448f2d3a27f7c7cd84"},{"cell_type":"code","metadata":{"source_hash":"af97ebf4","execution_start":1733506639200,"execution_millis":1,"execution_context_id":"2cf91b3b-32b6-4328-a2ae-eda3e2a6285c","cell_id":"0dfe3bb7792b4dd59f90a3adc2395656","deepnote_cell_type":"code"},"source":"history.history","block_group":"6de42fcd482041028f15190a9d724a9e","execution_count":33,"outputs":[{"output_type":"execute_result","execution_count":33,"data":{"text/plain":"{'loss': [0.45441532135009766,\n  0.26019325852394104,\n  0.15863880515098572,\n  0.0992484837770462,\n  0.08901619166135788,\n  0.07165495306253433,\n  0.06607170403003693,\n  0.057738833129405975,\n  0.05761871486902237,\n  0.04707843437790871,\n  0.04561035335063934,\n  0.044971369206905365,\n  0.04408722370862961],\n 'sparse_categorical_accuracy': [0.8006250262260437,\n  0.9006249904632568,\n  0.9456250071525574,\n  0.9599999785423279,\n  0.9624999761581421,\n  0.9768750071525574,\n  0.9750000238418579,\n  0.981249988079071,\n  0.9806249737739563,\n  0.9887499809265137,\n  0.9868749976158142,\n  0.9868749976158142,\n  0.9906250238418579],\n 'val_loss': [0.342609167098999,\n  0.14617864787578583,\n  0.10345589369535446,\n  0.12607049942016602,\n  0.13870616257190704,\n  0.09479240328073502,\n  0.15088890492916107,\n  0.07318870723247528,\n  0.1285814344882965,\n  0.11188601702451706,\n  0.11795833706855774,\n  0.09999417513608932,\n  0.12296637892723083],\n 'val_sparse_categorical_accuracy': [0.8650000095367432,\n  0.9200000166893005,\n  0.949999988079071,\n  0.9449999928474426,\n  0.9399999976158142,\n  0.949999988079071,\n  0.9300000071525574,\n  0.9599999785423279,\n  0.9399999976158142,\n  0.949999988079071,\n  0.9399999976158142,\n  0.9449999928474426,\n  0.9399999976158142],\n 'lr': [0.009506743,\n  0.009007243,\n  0.0085077435,\n  0.0080082435,\n  0.007508744,\n  0.007009244,\n  0.0065097436,\n  0.006010244,\n  0.0055107437,\n  0.005011244,\n  0.004511744,\n  0.004012244,\n  0.0035127443]}"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/395cc1f7-196e-457d-b9b5-bc644f411446","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"55286e08a6704a1391fd01e2471f594e","deepnote_cell_type":"markdown"},"source":"### Save the Model","block_group":"8c54a6fa50824e09b1816dc333e6c3c5"},{"cell_type":"code","metadata":{"source_hash":"82e1a854","execution_start":1733756761913,"execution_millis":7509,"execution_context_id":"02435cd0-a643-464f-a2a2-2611cdf83c53","cell_id":"29e0653051e54c03a60b39b3594fe517","deepnote_cell_type":"code"},"source":"import os\nfrom time import time\n\ntimestamp = int(time())\n\nsaved_model_dir = f'./saved_models/{timestamp}'\nif not os.path.exists(saved_model_dir):\n    os.makedirs(saved_model_dir)\nmodel_for_pruning.save(saved_model_dir)","block_group":"ec824ed73a174dcb93ac06d555c8ad11","execution_count":138,"outputs":[{"name":"stdout","text":"INFO:tensorflow:Assets written to: ./saved_models/1733756761/assets\nINFO:tensorflow:Assets written to: ./saved_models/1733756761/assets\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/0b822dc4-d4a4-46ee-aa68-6dc04f2614fd","content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"952fa5782b334655aa8f944dbf70e659","deepnote_cell_type":"text-cell-h3"},"source":"### TFLite Conversion","block_group":"d08b3d0269ba4bdcb77872760bcd3ffc"},{"cell_type":"code","metadata":{"source_hash":"db0e61c2","execution_start":1733506662583,"execution_millis":368,"execution_context_id":"2cf91b3b-32b6-4328-a2ae-eda3e2a6285c","cell_id":"6c7fab5085794429b8608a89dff89858","deepnote_cell_type":"code"},"source":"!ls saved_models","block_group":"05405b07d0724c9e917b3dd1627ddb90","execution_count":35,"outputs":[{"name":"stdout","text":"1733485351  1733496861\t1733498417  1733500854\t1733501673  1733502983\n1733495575  1733497584\t1733499278  1733501129\t1733502148  1733506242\n1733495848  1733498015\t1733500342  1733501442\t1733502504  1733506643\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/27a52553-66b0-4da2-a4eb-0e42acc3ccbe","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"235c2477","execution_start":1733756785956,"execution_millis":1,"execution_context_id":"02435cd0-a643-464f-a2a2-2611cdf83c53","cell_id":"7a37081c5c344de1b80a4224d1ec2b06","deepnote_cell_type":"code"},"source":"MODEL_NAME = 1733756761","block_group":"44fda3892e274f5b8e104b26eea7ac6c","execution_count":139,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"d18d3058","execution_start":1733756789429,"execution_millis":3355,"execution_context_id":"02435cd0-a643-464f-a2a2-2611cdf83c53","cell_id":"2647e8ca58504a408198885654388c5d","deepnote_cell_type":"code"},"source":"converter = tf.lite.TFLiteConverter.from_saved_model(f'./saved_models/{MODEL_NAME}')\ntflite_model = converter.convert()","block_group":"f93cc6c7ccb743e7b6ae968b213236d2","execution_count":140,"outputs":[{"name":"stderr","text":"2024-12-09 15:06:31.745082: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n2024-12-09 15:06:31.745525: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n2024-12-09 15:06:31.878865: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: ./saved_models/1733756761\n2024-12-09 15:06:32.041516: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n2024-12-09 15:06:32.041661: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: ./saved_models/1733756761\n2024-12-09 15:06:32.062484: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n2024-12-09 15:06:32.472914: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: ./saved_models/1733756761\n2024-12-09 15:06:32.518488: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 639638 microseconds.\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/83780a2c-87aa-4ddb-89b2-a12b0e4ae3e3","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"5eb9fb99","execution_start":1733756797135,"execution_millis":0,"execution_context_id":"02435cd0-a643-464f-a2a2-2611cdf83c53","cell_id":"ab42760c98294bf4980508fb637b54a4","deepnote_cell_type":"code"},"source":"tflite_models_dir = './tflite_models'\nif not os.path.exists(tflite_models_dir):\n    os.makedirs(tflite_models_dir)","block_group":"e9a31c351f5946788fa6cae3147d83ea","execution_count":141,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"9658f457","execution_start":1733756805058,"execution_millis":1,"execution_context_id":"02435cd0-a643-464f-a2a2-2611cdf83c53","cell_id":"3b05ad747e014784b8c3b73c95aee4cb","deepnote_cell_type":"code"},"source":"tflite_model_name = os.path.join(tflite_models_dir, f'{MODEL_NAME}.tflite')\ntflite_model_name","block_group":"bf6dd956d3454c0282b94225bf5d2fb8","execution_count":142,"outputs":[{"output_type":"execute_result","execution_count":142,"data":{"text/plain":"'./tflite_models/1733756761.tflite'"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/a9cf2277-e25e-41c4-b0db-e30ca342c764","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"90231985","execution_start":1733756810628,"execution_millis":246,"execution_context_id":"02435cd0-a643-464f-a2a2-2611cdf83c53","cell_id":"e0be1eaad2ce472c9642044b817f3e2b","deepnote_cell_type":"code"},"source":"with open(tflite_model_name, 'wb') as fp:\n    fp.write(tflite_model)","block_group":"0b4910f96dfe4e3bacafde2c91e711ea","execution_count":143,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"c060602f","execution_start":1733506680273,"execution_millis":568,"execution_context_id":"2cf91b3b-32b6-4328-a2ae-eda3e2a6285c","cell_id":"d379bfc5ba234f5c9ff8e2b148a310c8","deepnote_cell_type":"code"},"source":"!ls tflite_models","block_group":"d3d3369113284803a3ba71d734b4ffb4","execution_count":41,"outputs":[{"name":"stdout","text":"1733495575.tflite      1733498417.tflite.zip  1733501673.tflite\n1733495575.tflite.zip  1733499278.tflite      1733501673.tflite.zip\n1733495848.tflite      1733499278.tflite.zip  1733502148.tflite\n1733495848.tflite.zip  1733500342.tflite      1733502148.tflite.zip\n1733496861.tflite      1733500342.tflite.zip  1733502504.tflite\n1733496861.tflite.zip  1733500854.tflite      1733502504.tflite.zip\n1733497584.tflite      1733500854.tflite.zip  1733502983.tflite\n1733497584.tflite.zip  1733501129.tflite      1733502983.tflite.zip\n1733498015.tflite      1733501129.tflite.zip  1733506242.tflite\n1733498015.tflite.zip  1733501442.tflite      1733506242.tflite.zip\n1733498417.tflite      1733501442.tflite.zip  1733506643.tflite\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/e2835e29-431d-4fcb-8943-bdbd2e06cd2e","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"ec18d88","execution_start":1733756817025,"execution_millis":351,"execution_context_id":"02435cd0-a643-464f-a2a2-2611cdf83c53","cell_id":"85e5c7307db64549b2d60fe86513f406","deepnote_cell_type":"code"},"source":"import zipfile\n\nwith zipfile.ZipFile(f'{tflite_model_name}.zip', 'w', compression=zipfile.ZIP_DEFLATED) as f:\n    f.write(tflite_model_name)\n","block_group":"7cf17e98481a4c619b860fe03d19087f","execution_count":144,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=8a9d9526-dc21-42d6-ba37-8f708634743d' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"747e4e2559d649f498f8206a4914dc58"}}